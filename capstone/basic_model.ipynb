{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (230070, 32, 32, 1) (230070, 6)\n",
      "Validation set (5684, 32, 32, 1) (5684, 6)\n",
      "Test set (13068, 32, 32, 1) (13068, 6)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pickle_file = 'SVHN_multi.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "num_labels = 11\n",
    "num_channels = 1\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x_image = tf.placeholder(tf.float32, shape=(None, 32, 32, 1), name=\"x_image\")\n",
    "y = tf.placeholder(tf.int64, shape=(None, 6), name=\"y\")\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([4096, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.contrib.layers.flatten(h_pool2)\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_1 = weight_variable([1024, 11])\n",
    "b_1 = bias_variable([11])\n",
    "W_2 = weight_variable([1024, 11])\n",
    "b_2 = bias_variable([11])\n",
    "W_3 = weight_variable([1024, 11])\n",
    "b_3 = bias_variable([11])\n",
    "W_4 = weight_variable([1024, 11])\n",
    "b_4 = bias_variable([11])\n",
    "W_5 = weight_variable([1024, 11])\n",
    "b_5 = bias_variable([11])\n",
    "\n",
    "y_1 = tf.matmul(h_fc1_drop, W_1) + b_1\n",
    "y_2 = tf.matmul(h_fc1_drop, W_2) + b_2\n",
    "y_3 = tf.matmul(h_fc1_drop, W_3) + b_3\n",
    "y_4 = tf.matmul(h_fc1_drop, W_4) + b_4\n",
    "y_5 = tf.matmul(h_fc1_drop, W_5) + b_5\n",
    "\n",
    "y_pred = tf.stack([y_1,y_2,y_3,y_4,y_5])\n",
    "\n",
    "y_pred_class = tf.transpose(tf.argmax(y_pred, dimension=2))\n",
    "y_pred_class = tf.identity(y_pred_class, name='y_pred_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step 0, Batch accuracy 0\n",
      "Valid accuracy 0\n",
      "step 100, Batch accuracy 0.0234375\n",
      "Valid accuracy 0.00738916\n",
      "step 200, Batch accuracy 0.0234375\n",
      "Valid accuracy 0.0124912\n",
      "step 300, Batch accuracy 0.0234375\n",
      "Valid accuracy 0.0202322\n",
      "step 400, Batch accuracy 0.0234375\n",
      "Valid accuracy 0.0283251\n",
      "step 500, Batch accuracy 0.03125\n",
      "Valid accuracy 0.0376495\n",
      "step 600, Batch accuracy 0.078125\n",
      "Valid accuracy 0.0476777\n",
      "step 700, Batch accuracy 0.09375\n",
      "Valid accuracy 0.0666784\n",
      "step 800, Batch accuracy 0.0859375\n",
      "Valid accuracy 0.0798733\n",
      "step 900, Batch accuracy 0.117188\n",
      "Valid accuracy 0.0939479\n",
      "step 1000, Batch accuracy 0.164062\n",
      "Valid accuracy 0.110837\n",
      "step 1100, Batch accuracy 0.140625\n",
      "Valid accuracy 0.124736\n",
      "step 1200, Batch accuracy 0.125\n",
      "Valid accuracy 0.143561\n",
      "step 1300, Batch accuracy 0.195312\n",
      "Valid accuracy 0.161506\n",
      "step 1400, Batch accuracy 0.210938\n",
      "Valid accuracy 0.177692\n",
      "step 1500, Batch accuracy 0.203125\n",
      "Valid accuracy 0.194581\n",
      "step 1600, Batch accuracy 0.21875\n",
      "Valid accuracy 0.195285\n",
      "step 1700, Batch accuracy 0.28125\n",
      "Valid accuracy 0.226073\n",
      "step 1800, Batch accuracy 0.195312\n",
      "Valid accuracy 0.260732\n",
      "step 1900, Batch accuracy 0.257812\n",
      "Valid accuracy 0.276038\n",
      "step 2000, Batch accuracy 0.351562\n",
      "Valid accuracy 0.304539\n",
      "step 2100, Batch accuracy 0.335938\n",
      "Valid accuracy 0.316327\n",
      "step 2200, Batch accuracy 0.40625\n",
      "Valid accuracy 0.330401\n",
      "step 2300, Batch accuracy 0.4375\n",
      "Valid accuracy 0.345179\n",
      "step 2400, Batch accuracy 0.382812\n",
      "Valid accuracy 0.351161\n",
      "step 2500, Batch accuracy 0.390625\n",
      "Valid accuracy 0.36506\n",
      "step 2600, Batch accuracy 0.445312\n",
      "Valid accuracy 0.386524\n",
      "step 2700, Batch accuracy 0.5\n",
      "Valid accuracy 0.398663\n",
      "step 2800, Batch accuracy 0.5\n",
      "Valid accuracy 0.412386\n",
      "step 2900, Batch accuracy 0.40625\n",
      "Valid accuracy 0.425053\n",
      "step 3000, Batch accuracy 0.546875\n",
      "Valid accuracy 0.419423\n",
      "step 3100, Batch accuracy 0.484375\n",
      "Valid accuracy 0.442998\n",
      "step 3200, Batch accuracy 0.515625\n",
      "Valid accuracy 0.448452\n",
      "step 3300, Batch accuracy 0.492188\n",
      "Valid accuracy 0.454961\n",
      "step 3400, Batch accuracy 0.445312\n",
      "Valid accuracy 0.447396\n",
      "step 3500, Batch accuracy 0.53125\n",
      "Valid accuracy 0.457776\n",
      "step 3600, Batch accuracy 0.546875\n",
      "Valid accuracy 0.472555\n",
      "step 3700, Batch accuracy 0.546875\n",
      "Valid accuracy 0.494194\n",
      "step 3800, Batch accuracy 0.46875\n",
      "Valid accuracy 0.501935\n",
      "step 3900, Batch accuracy 0.578125\n",
      "Valid accuracy 0.509148\n",
      "step 4000, Batch accuracy 0.539062\n",
      "Valid accuracy 0.513019\n",
      "step 4100, Batch accuracy 0.578125\n",
      "Valid accuracy 0.523575\n",
      "step 4200, Batch accuracy 0.59375\n",
      "Valid accuracy 0.520936\n",
      "step 4300, Batch accuracy 0.617188\n",
      "Valid accuracy 0.52639\n",
      "step 4400, Batch accuracy 0.609375\n",
      "Valid accuracy 0.537474\n",
      "step 4500, Batch accuracy 0.585938\n",
      "Valid accuracy 0.539585\n",
      "step 4600, Batch accuracy 0.601562\n",
      "Valid accuracy 0.545391\n",
      "step 4700, Batch accuracy 0.59375\n",
      "Valid accuracy 0.5519\n",
      "step 4800, Batch accuracy 0.65625\n",
      "Valid accuracy 0.548909\n",
      "step 4900, Batch accuracy 0.625\n",
      "Valid accuracy 0.562104\n",
      "step 5000, Batch accuracy 0.59375\n",
      "Valid accuracy 0.565799\n",
      "step 5100, Batch accuracy 0.640625\n",
      "Valid accuracy 0.564391\n",
      "step 5200, Batch accuracy 0.578125\n",
      "Valid accuracy 0.556474\n",
      "step 5300, Batch accuracy 0.585938\n",
      "Valid accuracy 0.559113\n",
      "step 5400, Batch accuracy 0.71875\n",
      "Valid accuracy 0.576179\n",
      "step 5500, Batch accuracy 0.601562\n",
      "Valid accuracy 0.592013\n",
      "step 5600, Batch accuracy 0.695312\n",
      "Valid accuracy 0.595707\n",
      "step 5700, Batch accuracy 0.710938\n",
      "Valid accuracy 0.5943\n",
      "step 5800, Batch accuracy 0.640625\n",
      "Valid accuracy 0.594476\n",
      "step 5900, Batch accuracy 0.664062\n",
      "Valid accuracy 0.603448\n",
      "step 6000, Batch accuracy 0.664062\n",
      "Valid accuracy 0.597115\n",
      "step 6100, Batch accuracy 0.578125\n",
      "Valid accuracy 0.612069\n",
      "step 6200, Batch accuracy 0.703125\n",
      "Valid accuracy 0.60943\n",
      "step 6300, Batch accuracy 0.710938\n",
      "Valid accuracy 0.610486\n",
      "step 6400, Batch accuracy 0.671875\n",
      "Valid accuracy 0.617171\n",
      "step 6500, Batch accuracy 0.632812\n",
      "Valid accuracy 0.622273\n",
      "step 6600, Batch accuracy 0.703125\n",
      "Valid accuracy 0.617347\n",
      "step 6700, Batch accuracy 0.625\n",
      "Valid accuracy 0.623856\n",
      "step 6800, Batch accuracy 0.765625\n",
      "Valid accuracy 0.623681\n",
      "step 6900, Batch accuracy 0.671875\n",
      "Valid accuracy 0.623681\n",
      "step 7000, Batch accuracy 0.570312\n",
      "Valid accuracy 0.619986\n",
      "step 7100, Batch accuracy 0.726562\n",
      "Valid accuracy 0.622449\n",
      "step 7200, Batch accuracy 0.648438\n",
      "Valid accuracy 0.63019\n",
      "step 7300, Batch accuracy 0.710938\n",
      "Valid accuracy 0.634061\n",
      "step 7400, Batch accuracy 0.742188\n",
      "Valid accuracy 0.644792\n",
      "step 7500, Batch accuracy 0.71875\n",
      "Valid accuracy 0.641977\n",
      "step 7600, Batch accuracy 0.71875\n",
      "Valid accuracy 0.640218\n",
      "step 7700, Batch accuracy 0.695312\n",
      "Valid accuracy 0.649543\n",
      "step 7800, Batch accuracy 0.679688\n",
      "Valid accuracy 0.640042\n",
      "step 7900, Batch accuracy 0.789062\n",
      "Valid accuracy 0.65095\n",
      "step 8000, Batch accuracy 0.6875\n",
      "Valid accuracy 0.65183\n",
      "step 8100, Batch accuracy 0.8125\n",
      "Valid accuracy 0.6557\n",
      "step 8200, Batch accuracy 0.703125\n",
      "Valid accuracy 0.659571\n",
      "step 8300, Batch accuracy 0.78125\n",
      "Valid accuracy 0.661682\n",
      "step 8400, Batch accuracy 0.695312\n",
      "Valid accuracy 0.651126\n",
      "step 8500, Batch accuracy 0.757812\n",
      "Valid accuracy 0.665904\n",
      "step 8600, Batch accuracy 0.6875\n",
      "Valid accuracy 0.661506\n",
      "step 8700, Batch accuracy 0.773438\n",
      "Valid accuracy 0.658867\n",
      "step 8800, Batch accuracy 0.71875\n",
      "Valid accuracy 0.662737\n",
      "step 8900, Batch accuracy 0.648438\n",
      "Valid accuracy 0.656932\n",
      "step 9000, Batch accuracy 0.796875\n",
      "Valid accuracy 0.664321\n",
      "step 9100, Batch accuracy 0.71875\n",
      "Valid accuracy 0.667136\n",
      "step 9200, Batch accuracy 0.710938\n",
      "Valid accuracy 0.678571\n",
      "step 9300, Batch accuracy 0.796875\n",
      "Valid accuracy 0.680683\n",
      "step 9400, Batch accuracy 0.8125\n",
      "Valid accuracy 0.675229\n",
      "step 9500, Batch accuracy 0.726562\n",
      "Valid accuracy 0.674349\n",
      "step 9600, Batch accuracy 0.773438\n",
      "Valid accuracy 0.680155\n",
      "step 9700, Batch accuracy 0.789062\n",
      "Valid accuracy 0.681738\n",
      "step 9800, Batch accuracy 0.726562\n",
      "Valid accuracy 0.684201\n",
      "step 9900, Batch accuracy 0.734375\n",
      "Valid accuracy 0.685609\n",
      "step 10000, Batch accuracy 0.71875\n",
      "Valid accuracy 0.682442\n",
      "step 10100, Batch accuracy 0.78125\n",
      "Valid accuracy 0.687016\n",
      "step 10200, Batch accuracy 0.796875\n",
      "Valid accuracy 0.683849\n",
      "step 10300, Batch accuracy 0.757812\n",
      "Valid accuracy 0.686664\n",
      "step 10400, Batch accuracy 0.789062\n",
      "Valid accuracy 0.685433\n",
      "step 10500, Batch accuracy 0.742188\n",
      "Valid accuracy 0.684729\n",
      "step 10600, Batch accuracy 0.65625\n",
      "Valid accuracy 0.689127\n",
      "step 10700, Batch accuracy 0.757812\n",
      "Valid accuracy 0.685081\n",
      "step 10800, Batch accuracy 0.789062\n",
      "Valid accuracy 0.686664\n",
      "step 10900, Batch accuracy 0.726562\n",
      "Valid accuracy 0.693878\n",
      "step 11000, Batch accuracy 0.742188\n",
      "Valid accuracy 0.700563\n",
      "step 11100, Batch accuracy 0.789062\n",
      "Valid accuracy 0.699859\n",
      "step 11200, Batch accuracy 0.804688\n",
      "Valid accuracy 0.698628\n",
      "step 11300, Batch accuracy 0.773438\n",
      "Valid accuracy 0.707776\n",
      "step 11400, Batch accuracy 0.773438\n",
      "Valid accuracy 0.701267\n",
      "step 11500, Batch accuracy 0.75\n",
      "Valid accuracy 0.698804\n",
      "step 11600, Batch accuracy 0.804688\n",
      "Valid accuracy 0.700387\n",
      "step 11700, Batch accuracy 0.765625\n",
      "Valid accuracy 0.708128\n",
      "step 11800, Batch accuracy 0.8125\n",
      "Valid accuracy 0.703906\n",
      "step 11900, Batch accuracy 0.75\n",
      "Valid accuracy 0.700035\n",
      "step 12000, Batch accuracy 0.765625\n",
      "Valid accuracy 0.710767\n",
      "step 12100, Batch accuracy 0.789062\n",
      "Valid accuracy 0.709184\n",
      "step 12200, Batch accuracy 0.859375\n",
      "Valid accuracy 0.7076\n",
      "step 12300, Batch accuracy 0.734375\n",
      "Valid accuracy 0.708832\n",
      "step 12400, Batch accuracy 0.78125\n",
      "Valid accuracy 0.70936\n",
      "step 12500, Batch accuracy 0.734375\n",
      "Valid accuracy 0.706721\n",
      "step 12600, Batch accuracy 0.742188\n",
      "Valid accuracy 0.70848\n",
      "step 12700, Batch accuracy 0.828125\n",
      "Valid accuracy 0.713582\n",
      "step 12800, Batch accuracy 0.742188\n",
      "Valid accuracy 0.720091\n",
      "step 12900, Batch accuracy 0.8125\n",
      "Valid accuracy 0.722555\n",
      "step 13000, Batch accuracy 0.8125\n",
      "Valid accuracy 0.721499\n",
      "step 13100, Batch accuracy 0.84375\n",
      "Valid accuracy 0.725018\n",
      "step 13200, Batch accuracy 0.804688\n",
      "Valid accuracy 0.713054\n",
      "step 13300, Batch accuracy 0.789062\n",
      "Valid accuracy 0.720443\n",
      "step 13400, Batch accuracy 0.757812\n",
      "Valid accuracy 0.725369\n",
      "step 13500, Batch accuracy 0.796875\n",
      "Valid accuracy 0.732935\n",
      "step 13600, Batch accuracy 0.796875\n",
      "Valid accuracy 0.725018\n",
      "step 13700, Batch accuracy 0.804688\n",
      "Valid accuracy 0.71974\n",
      "step 13800, Batch accuracy 0.84375\n",
      "Valid accuracy 0.730471\n",
      "step 13900, Batch accuracy 0.804688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy 0.72924\n",
      "step 14000, Batch accuracy 0.859375\n",
      "Valid accuracy 0.726777\n",
      "step 14100, Batch accuracy 0.835938\n",
      "Valid accuracy 0.727657\n",
      "step 14200, Batch accuracy 0.71875\n",
      "Valid accuracy 0.726249\n",
      "step 14300, Batch accuracy 0.78125\n",
      "Valid accuracy 0.719916\n",
      "step 14400, Batch accuracy 0.804688\n",
      "Valid accuracy 0.73012\n",
      "step 14500, Batch accuracy 0.828125\n",
      "Valid accuracy 0.730471\n",
      "step 14600, Batch accuracy 0.875\n",
      "Valid accuracy 0.739268\n",
      "step 14700, Batch accuracy 0.773438\n",
      "Valid accuracy 0.73311\n",
      "step 14800, Batch accuracy 0.859375\n",
      "Valid accuracy 0.737333\n",
      "step 14900, Batch accuracy 0.828125\n",
      "Valid accuracy 0.737333\n",
      "step 15000, Batch accuracy 0.789062\n",
      "Valid accuracy 0.733638\n",
      "step 15100, Batch accuracy 0.8125\n",
      "Valid accuracy 0.736981\n",
      "step 15200, Batch accuracy 0.835938\n",
      "Valid accuracy 0.730999\n",
      "step 15300, Batch accuracy 0.828125\n",
      "Valid accuracy 0.74525\n",
      "step 15400, Batch accuracy 0.84375\n",
      "Valid accuracy 0.738037\n",
      "step 15500, Batch accuracy 0.859375\n",
      "Valid accuracy 0.735749\n",
      "step 15600, Batch accuracy 0.75\n",
      "Valid accuracy 0.744898\n",
      "step 15700, Batch accuracy 0.8125\n",
      "Valid accuracy 0.740148\n",
      "step 15800, Batch accuracy 0.84375\n",
      "Valid accuracy 0.73962\n",
      "step 15900, Batch accuracy 0.851562\n",
      "Valid accuracy 0.742963\n",
      "step 16000, Batch accuracy 0.757812\n",
      "Valid accuracy 0.737157\n",
      "step 16100, Batch accuracy 0.796875\n",
      "Valid accuracy 0.738037\n",
      "step 16200, Batch accuracy 0.882812\n",
      "Valid accuracy 0.739972\n",
      "step 16300, Batch accuracy 0.773438\n",
      "Valid accuracy 0.745602\n",
      "step 16400, Batch accuracy 0.875\n",
      "Valid accuracy 0.747537\n",
      "step 16500, Batch accuracy 0.820312\n",
      "Valid accuracy 0.747537\n",
      "step 16600, Batch accuracy 0.84375\n",
      "Valid accuracy 0.74912\n",
      "step 16700, Batch accuracy 0.835938\n",
      "Valid accuracy 0.752991\n",
      "step 16800, Batch accuracy 0.8125\n",
      "Valid accuracy 0.748065\n",
      "step 16900, Batch accuracy 0.882812\n",
      "Valid accuracy 0.747537\n",
      "step 17000, Batch accuracy 0.820312\n",
      "Valid accuracy 0.747185\n",
      "step 17100, Batch accuracy 0.851562\n",
      "Valid accuracy 0.751407\n",
      "step 17200, Batch accuracy 0.875\n",
      "Valid accuracy 0.750352\n",
      "step 17300, Batch accuracy 0.914062\n",
      "Valid accuracy 0.741907\n",
      "step 17400, Batch accuracy 0.796875\n",
      "Valid accuracy 0.753519\n",
      "step 17500, Batch accuracy 0.867188\n",
      "Valid accuracy 0.752287\n",
      "step 17600, Batch accuracy 0.867188\n",
      "Valid accuracy 0.747713\n",
      "step 17700, Batch accuracy 0.804688\n",
      "Valid accuracy 0.750528\n",
      "step 17800, Batch accuracy 0.75\n",
      "Valid accuracy 0.74613\n",
      "step 17900, Batch accuracy 0.78125\n",
      "Valid accuracy 0.748241\n",
      "step 18000, Batch accuracy 0.875\n",
      "Valid accuracy 0.756861\n",
      "step 18100, Batch accuracy 0.835938\n",
      "Valid accuracy 0.751583\n",
      "step 18200, Batch accuracy 0.796875\n",
      "Valid accuracy 0.755278\n",
      "step 18300, Batch accuracy 0.820312\n",
      "Valid accuracy 0.759676\n",
      "step 18400, Batch accuracy 0.882812\n",
      "Valid accuracy 0.7595\n",
      "step 18500, Batch accuracy 0.84375\n",
      "Valid accuracy 0.758973\n",
      "step 18600, Batch accuracy 0.882812\n",
      "Valid accuracy 0.754222\n",
      "step 18700, Batch accuracy 0.828125\n",
      "Valid accuracy 0.754046\n",
      "step 18800, Batch accuracy 0.859375\n",
      "Valid accuracy 0.754398\n",
      "step 18900, Batch accuracy 0.890625\n",
      "Valid accuracy 0.760556\n",
      "step 19000, Batch accuracy 0.898438\n",
      "Valid accuracy 0.756509\n",
      "step 19100, Batch accuracy 0.867188\n",
      "Valid accuracy 0.757565\n",
      "step 19200, Batch accuracy 0.859375\n",
      "Valid accuracy 0.764075\n",
      "step 19300, Batch accuracy 0.835938\n",
      "Valid accuracy 0.76126\n",
      "step 19400, Batch accuracy 0.851562\n",
      "Valid accuracy 0.751056\n",
      "step 19500, Batch accuracy 0.890625\n",
      "Valid accuracy 0.761084\n",
      "step 19600, Batch accuracy 0.820312\n",
      "Valid accuracy 0.755806\n",
      "step 19700, Batch accuracy 0.859375\n",
      "Valid accuracy 0.756861\n",
      "step 19800, Batch accuracy 0.882812\n",
      "Valid accuracy 0.762315\n",
      "step 19900, Batch accuracy 0.796875\n",
      "Valid accuracy 0.760556\n",
      "step 20000, Batch accuracy 0.9375\n",
      "Valid accuracy 0.767417\n",
      "Test accuracy 0.789486\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f613744bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size=128\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y[:,1], logits=y_1) +\n",
    "                              tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y[:,2], logits=y_2) +\n",
    "                              tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y[:,3], logits=y_3) +\n",
    "                              tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y[:,4], logits=y_4) +\n",
    "                              tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y[:,5], logits=y_5))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_predictions = tf.reduce_min(tf.cast(tf.equal(y_pred_class,y[:,1:]), tf.float32),1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name=\"accuracy\")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Initialized')\n",
    "accuracy_curve = []\n",
    "for step in range(20001):\n",
    "    offset = (step * batch_size) % (train_dataset.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    if step%100 == 0:\n",
    "        acc = sess.run(accuracy,feed_dict={x_image : batch_data, y : batch_labels, keep_prob : 1.0})\n",
    "        print(\"step %d, Batch accuracy %g\"%(step, acc))\n",
    "        acc = sess.run(accuracy,feed_dict={x_image : valid_dataset, y : valid_labels, keep_prob : 1.0}) \n",
    "        print(\"Valid accuracy %g\"%acc)\n",
    "        accuracy_curve.append((step,100.0*acc))\n",
    "    train_step.run(feed_dict={x_image: batch_data, y : batch_labels, keep_prob: 0.5})\n",
    "acc = sess.run(accuracy,feed_dict={x_image : test_dataset, y : test_labels, keep_prob : 1.0}) \n",
    "print(\"Test accuracy %g\"%acc)\n",
    "accuracy_curve.append((20001,100.0*acc))\n",
    "save_model_path = './multi_digit_classification'\n",
    "# Save Model\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, save_model_path)\n",
    "\n",
    "plt.plot(*zip(*accuracy_curve))\n",
    "plt.title('Basic Over Training Iterations')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('% Images Classified Correctly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./multi_digit_classification\n",
      "Testing Accuracy: 0.25\n",
      "\n",
      "Predicted:  [ 2  3  9 10 10]  Actual:  [6, 2, 3, 9, 5]\n",
      "Predicted:  [ 5 10 10 10 10]  Actual:  [5, 10, 10, 10, 10]\n",
      "Predicted:  [ 2  0  0 10 10]  Actual:  [6, 3, 4, 1, 9]\n",
      "Predicted:  [ 4  0  4  4 10]  Actual:  [1, 4, 0, 4, 1]\n",
      "Predicted:  [ 5 10 10 10 10]  Actual:  [5, 10, 10, 10, 10]\n",
      "Predicted:  [ 1  3  3  5 10]  Actual:  [1, 5, 5, 9, 5]\n",
      "Predicted:  [ 3  5 10 10 10]  Actual:  [5, 5, 10, 10, 10]\n",
      "Predicted:  [ 1  2  3 10 10]  Actual:  [1, 2, 3, 10, 10]\n",
      "Predicted:  [ 7  0  5 10 10]  Actual:  [7, 0, 5, 10, 10]\n",
      "Predicted:  [ 5  9  9  0 10]  Actual:  [1, 3, 3, 3, 0]\n",
      "Predicted:  [ 1  5 10 10 10]  Actual:  [1, 5, 10, 10, 10]\n",
      "Predicted:  [ 3  1  7 10 10]  Actual:  [1, 9, 1, 7, 7]\n",
      "Predicted:  [ 2  1  5 10 10]  Actual:  [7, 1, 8, 10, 10]\n",
      "Predicted:  [ 4  6  6 10 10]  Actual:  [1, 4, 6, 6, 4]\n",
      "Predicted:  [ 1  5 10 10 10]  Actual:  [1, 2, 5, 5, 7]\n",
      "Predicted:  [ 5  4  6 10 10]  Actual:  [5, 8, 4, 1, 10]\n",
      "Predicted:  [ 3  9  8  2 10]  Actual:  [3, 5, 9, 8, 2]\n",
      "Predicted:  [ 4  7  1  6 10]  Actual:  [2, 1, 7, 1, 3]\n",
      "Predicted:  [ 6  3  1 10 10]  Actual:  [1, 6, 3, 1, 4]\n",
      "Predicted:  [ 2  8 10 10 10]  Actual:  [2, 3, 10, 10, 10]\n",
      "Percentage of digit 5 predicted blank:  100.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "save_model_path = './multi_digit_classification'\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    pickle_file = 'google_images.pickle'\n",
    "\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        gtest_features = save['real_test_dataset']\n",
    "        gtest_labels = save['real_test_labels']\n",
    "        del save  # hint to help gc free up memory\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x_image:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('y_pred_class:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Check accuracy in predicting images taken from Google images\n",
    "        test_batch_acc_total, predictions = sess.run(\n",
    "                [loaded_acc,loaded_logits],\n",
    "                feed_dict={loaded_x: gtest_features, loaded_y: gtest_labels, loaded_keep_prob: 1.0})\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total))\n",
    "        for i in range(len(predictions)):\n",
    "            print('Predicted: ',predictions[i],' Actual: ',gtest_labels[i][1:])\n",
    "            \n",
    "        predictions = sess.run(loaded_logits, \n",
    "                               feed_dict={loaded_x : test_dataset, loaded_y : test_labels, loaded_keep_prob : 1.0})\n",
    "        \n",
    "        blanks = 0\n",
    "        for pred in predictions:\n",
    "            if pred[4] == 10:\n",
    "                blanks += 1\n",
    "        print('Percentage of digit 5 predicted blank: ', 100.0 * blanks/test_labels.shape[0])\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
